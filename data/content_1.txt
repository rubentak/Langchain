





Welcome to LangChain â€” ðŸ¦œðŸ”— LangChain 0.0.173















































Skip to main content










Ctrl+K












ðŸ¦œðŸ”— LangChain 0.0.173



Getting Started

Quickstart Guide
Concepts
Tutorials

Modules

Models
Getting Started
LLMs
Getting Started
Generic Functionality
How to use the async API for LLMs
How to write a custom LLM wrapper
How (and why) to use the fake LLM
How (and why) to use the the human input LLM
How to cache LLM calls
How to serialize LLM classes
How to stream LLM and Chat Model responses
How to track token usage


Integrations
AI21
Aleph Alpha
Anyscale
Azure OpenAI
Banana
CerebriumAI
Cohere
DeepInfra
ForefrontAI
GooseAI
GPT4All
Hugging Face Hub
Hugging Face Local Pipelines
Huggingface TextGen Inference
Structured Decoding with JSONFormer
Llama-cpp
Manifest
Modal
NLP Cloud
OpenAI
Petals
PipelineAI
PredictionGuard
PromptLayer OpenAI
Structured Decoding with RELLM
Replicate
Runhouse
SageMakerEndpoint
StochasticAI
Writer


Reference


Chat Models
Getting Started
How-To Guides
How to use few shot examples
How to stream responses


Integrations
Anthropic
Azure
OpenAI
PromptLayer ChatOpenAI




Text Embedding Models
Aleph Alpha
AzureOpenAI
Cohere
Fake Embeddings
Hugging Face Hub
InstructEmbeddings
Jina
Llama-cpp
OpenAI
SageMaker Endpoint Embeddings
Self Hosted Embeddings
Sentence Transformers Embeddings
TensorflowHub




Prompts
Getting Started
Prompt Templates
Getting Started
How-To Guides
Connecting to a Feature Store
How to create a custom prompt template
How to create a prompt template that uses few shot examples
How to work with partial Prompt Templates
How to serialize prompts


Reference
PromptTemplates
Example Selector
Output Parsers




Chat Prompt Template
Example Selectors
How to create a custom example selector
LengthBased ExampleSelector
Maximal Marginal Relevance ExampleSelector
NGram Overlap ExampleSelector
Similarity ExampleSelector


Output Parsers
Output Parsers
CommaSeparatedListOutputParser
OutputFixingParser
PydanticOutputParser
RetryOutputParser
Structured Output Parser




Indexes
Getting Started
Document Loaders
CoNLL-U
Copy Paste
CSV
Email
EPub
EverNote
Facebook Chat
File Directory
HTML
Images
Jupyter Notebook
Markdown
Microsoft PowerPoint
Microsoft Word
Pandas DataFrame
PDF
Sitemap
Subtitle
Telegram
TOML
Unstructured File
URL
WebBaseLoader
WhatsApp Chat
Arxiv
AZLyrics
BiliBili
College Confidential
Gutenberg
Hacker News
HuggingFace dataset
iFixit
IMSDb
MediaWikiDump
YouTube transcripts
Airbyte JSON
Apify Dataset
AWS S3 Directory
AWS S3 File
Azure Blob Storage Container
Azure Blob Storage File
Blackboard
Blockchain
ChatGPT Data
Confluence
Diffbot
Discord
Docugami
DuckDB
Figma
GitBook
Git
Google BigQuery
Google Cloud Storage Directory
Google Cloud Storage File
Google Drive
Image captions
Microsoft OneDrive
Modern Treasury
Notion DB 2/2
Notion DB 1/2
Obsidian
ReadTheDocs Documentation
Reddit
Roam
Slack
Spreedly
Stripe
Twitter


Text Splitters
Getting Started
Character
LaTeX
Markdown
NLTK
Python Code
Recursive Character
spaCy
Tiktoken
Hugging Face tokenizer
tiktoken (OpenAI) tokenizer


Vectorstores
Getting Started
AnalyticDB
Annoy
AtlasDB
Chroma
Deep Lake
DocArrayHnswSearch
DocArrayInMemorySearch
ElasticSearch
FAISS
LanceDB
Milvus
MyScale
OpenSearch
PGVector
Pinecone
Qdrant
Redis
Supabase (Postgres)
Tair
Weaviate
Zilliz


Retrievers
Arxiv
Azure Cognitive Search Retriever
ChatGPT Plugin
Self-querying with Chroma
Cohere Reranker
Contextual Compression
Databerry
ElasticSearch BM25
kNN
Metal
Pinecone Hybrid Search
Self-querying
SVM
TF-IDF
Time Weighted VectorStore
VectorStore
Vespa
Weaviate Hybrid Search
Wikipedia




Memory
Getting Started
How-To Guides
ConversationBufferMemory
ConversationBufferWindowMemory
Entity Memory
Conversation Knowledge Graph Memory
ConversationSummaryMemory
ConversationSummaryBufferMemory
ConversationTokenBufferMemory
VectorStore-Backed Memory
How to add Memory to an LLMChain
How to add memory to a Multi-Input Chain
How to add Memory to an Agent
Adding Message Memory backed by a database to an Agent
Cassandra Chat Message History
How to customize conversational memory
How to create a custom Memory class
Mongodb Chat Message History
MotÃ¶rhead Memory
How to use multiple memory classes in the same chain
Postgres Chat Message History
Redis Chat Message History
Zep Memory




Chains
Getting Started
How-To Guides
Async API for Chain
Creating a custom Chain
Loading from LangChainHub
LLM Chain
Router Chains
Sequential Chains
Serialization
Transformation Chain
Analyze Document
Chat Over Documents with Chat History
Graph QA
Hypothetical Document Embeddings
Question Answering with Sources
Question Answering
Summarization
Retrieval Question/Answering
Retrieval Question Answering with Sources
Vector DB Text Generation
API Chains
Self-Critique Chain with Constitutional AI
FLARE
BashChain
LLMCheckerChain
LLM Math
LLMRequestsChain
LLMSummarizationCheckerChain
Moderation
Router Chains: Selecting from multiple prompts with MultiPromptChain
Router Chains: Selecting from multiple prompts with MultiRetrievalQAChain
OpenAPI Chain
PAL
SQL Chain example


Reference


Agents
Getting Started
Tools
Getting Started
Defining Custom Tools
Multi-Input Tools
Tool Input Schema
Apify
ArXiv API Tool
AWS Lambda API
Shell Tool
Bing Search
ChatGPT Plugins
DuckDuckGo Search
File System Tools
Google Places
Google Search
Google Serper API
Gradio Tools
GraphQL tool
HuggingFace Tools
Human as a tool
IFTTT WebHooks
Metaphor Search
OpenWeatherMap API
Python REPL
Requests
SceneXplain
Search Tools
SearxNG Search API
SerpAPI
Wikipedia
Wolfram Alpha
YouTubeSearchTool
Zapier Natural Language Actions API


Agents
Agent Types
Custom Agent
Custom LLM Agent
Custom LLM Agent (with a ChatModel)
Custom MRKL Agent
Custom MultiAction Agent
Custom Agent with Tool Retrieval
Conversation Agent (for Chat Models)
Conversation Agent
MRKL
MRKL Chat
ReAct
Self Ask With Search
Structured Tool Chat Agent


Toolkits
CSV Agent
Gmail Toolkit
Jira
JSON Agent
OpenAPI agents
Natural Language APIs
Pandas Dataframe Agent
PlayWright Browser Toolkit
PowerBI Dataset Agent
Python Agent
Spark Dataframe Agent
SQL Database Agent
Vectorstore Agent


Agent Executors
How to combine agents and vectorstores
How to use the async API for Agents
How to create ChatGPT Clone
Handle Parsing Errors
How to access intermediate steps
How to cap the max number of iterations
How to use a timeout for the agent
How to add SharedMemory to an Agent and its Tools


Plan and Execute


Callbacks

Use Cases

Autonomous Agents
Agent Simulations
Agents
Question Answering over Docs
Chatbots
Querying Tabular Data
Code Understanding
Interacting with APIs
Summarization
Extraction
Evaluation
Agent Benchmarking: Search + Calculator
Agent VectorDB Question Answering Benchmarking
Benchmarking Template
Data Augmented Question Answering
Generic Agent Evaluation
Using Hugging Face Datasets
LLM Math
Evaluating an OpenAPI Chain
Question Answering Benchmarking: Paul Graham Essay
Question Answering Benchmarking: State of the Union Address
QA Generation
Question Answering
SQL Question Answering Benchmarking: Chinook



Reference

Installation
API References
Models
LLMs
Chat Models
Embeddings


Prompts
PromptTemplates
Example Selector
Output Parsers


Indexes
Docstore
Text Splitter
Document Loaders
Vector Stores
Retrievers
Document Compressors
Document Transformers


Memory
Chains
Agents
Agents
Tools
Agent Toolkits


Utilities
Experimental Modules



Ecosystem

Integrations
AI21 Labs
Aim
AnalyticDB
Anyscale
Apify
AtlasDB
Banana
CerebriumAI
Chroma
ClearML Integration
Cohere
Comet
Databerry
DeepInfra
Deep Lake
Docugami
ForefrontAI
Google Search
Google Serper
GooseAI
GPT4All
Graphsignal
Hazy Research
Helicone
Hugging Face
Jina
LanceDB
Llama.cpp
Metal
Milvus
MLflow
Modal
MyScale
NLPCloud
OpenAI
OpenSearch
OpenWeatherMap API
Petals
PGVector
Pinecone
PipelineAI
Prediction Guard
PromptLayer
Qdrant
Rebuff: Prompt Injection Detection with LangChain
Redis
Replicate
Runhouse
RWKV-4
SearxNG Search API
SerpAPI
StochasticAI
Tair
Unstructured
Weights & Biases
Weaviate
Wolfram Alpha Wrapper
Writer
Yeager.ai
Zilliz


Dependents

Additional Resources

LangChainHub
Gallery
Deployments
Tracing
Model Comparison
Discord
YouTube
Production Support








































.rst







.pdf



















Welcome to LangChain




 Contents 



Getting Started
Modules
Use Cases
Reference Docs
Ecosystem
Additional Resources








Welcome to LangChain#

LangChain is a framework for developing applications powered by language models. We believe that the most powerful and differentiated applications will not only call out to a language model, but will also be:


Data-aware: connect a language model to other sources of data
Agentic: allow a language model to interact with its environment


The LangChain framework is designed around these principles.


This is the Python specific portion of the documentation. For a purely conceptual guide to LangChain, see here. For the JavaScript documentation, see here.


Getting Started#

How to get started using LangChain to create an Language Model application.


Quickstart Guide


Concepts and terminology.


Concepts and terminology


Tutorials created by community experts and presented on YouTube.


Tutorials





Modules#

These modules are the core abstractions which we view as the building blocks of any LLM-powered application.

For each module LangChain provides standard, extendable interfaces. LangChain also provides external integrations and even end-to-end implementations for off-the-shelf use.

The docs for each module contain quickstart examples, how-to guides, reference docs, and conceptual guides.


The modules are (from least to most complex):


Models: Supported model types and integrations.
Prompts: Prompt management, optimization, and serialization.
Memory: Memory refers to state that is persisted between calls of a chain/agent.
Indexes: Language models become much more powerful when combined with application-specific data - this module contains interfaces and integrations for loading, querying and updating external data.
Chains: Chains are structured sequences of calls (to an LLM or to a different utility).
Agents: An agent is a Chain in which an LLM, given a high-level directive and a set of tools, repeatedly decides an action, executes the action and observes the outcome until the high-level directive is complete.
Callbacks: Callbacks let you log and stream the intermediate steps of any chain, making it easy to observe, debug, and evaluate the internals of an application.





Use Cases#

Best practices and built-in implementations for common LangChain use cases:


Autonomous Agents: Autonomous agents are long-running agents that take many steps in an attempt to accomplish an objective. Examples include AutoGPT and BabyAGI.
Agent Simulations: Putting agents in a sandbox and observing how they interact with each other and react to events can be an effective way to evaluate their long-range reasoning and planning abilities.
Personal Assistants: One of the primary LangChain use cases. Personal assistants need to take actions, remember interactions, and have knowledge about your data.
Question Answering: Another common LangChain use case. Answering questions over specific documents, only utilizing the information in those documents to construct an answer.
Chatbots: Language models love to chat, making this a very natural use of them.
Querying Tabular Data: Recommended reading if you want to use language models to query structured data (CSVs, SQL, dataframes, etc).
Code Understanding: Recommended reading if you want to use language models to analyze code.
Interacting with APIs: Enabling language models to interact with APIs is extremely powerful. It gives them access to up-to-date information and allows them to take actions.
Extraction: Extract structured information from text.
Summarization: Compressing longer documents. A type of Data-Augmented Generation.
Evaluation: Generative models are hard to evaluate with traditional metrics. One promising approach is to use language models themselves to do the evaluation.





Reference Docs#

Full documentation on all methods, classes, installation methods, and integration setups for LangChain.


Reference Documentation





Ecosystem#

LangChain integrates a lot of different LLMs, systems, and products.

From the other side, many systems and products depend on LangChain.
It creates a vibrant and thriving ecosystem.

Integrations: Guides for how other products can be used with LangChain.
Dependents: List of repositories that use LangChain.





Additional Resources#

Additional resources we think may be useful as you develop your application!


LangChainHub: The LangChainHub is a place to share and explore other prompts, chains, and agents.
Gallery: A collection of great projects that use Langchain, compiled by the folks at Kyrolabs. Useful for finding inspiration and example implementations.
Deployments: A collection of instructions, code snippets, and template repositories for deploying LangChain apps.
Tracing: A guide on using tracing in LangChain to visualize the execution of chains and agents.
Model Laboratory: Experimenting with different prompts, models, and chains is a big part of developing the best possible application. The ModelLaboratory makes it easy to do so.
Discord: Join us on our Discord to discuss all things LangChain!
YouTube: A collection of the LangChain tutorials and videos.
Production Support: As you move your LangChains into production, weâ€™d love to offer more comprehensive support. Please fill out this form and weâ€™ll set up a dedicated support Slack channel.











next
Quickstart Guide









 Contents
  


Getting Started
Modules
Use Cases
Reference Docs
Ecosystem
Additional Resources









By Harrison Chase




    
      Â© Copyright 2023, Harrison Chase.
      




  Last updated on May 18, 2023.
  















