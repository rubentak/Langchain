{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# langchain Chains\n",
    "\n",
    "in this notebook we will take a look at different langchain chains"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# install the packages\n",
    "!pip install -Uqqq pip --progress-bar off\n",
    "!pip install -qqq langchain==0.0.149 --progress-bar off\n",
    "!pip install -qqq openai==0.27.4 --progress-bar off\n",
    "!pip install -qqq tiktoken==0.3.3 --progress-bar off\n",
    "!pip install -qqq watermark==2.3.1 --progress-bar off\n",
    "!pip install -qqq chromadb==0.3.21 --progress-bar off"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T13:51:21.366806Z",
     "start_time": "2023-05-04T13:50:58.622673Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import os\n",
    "import textwrap\n",
    "from getpass import getpass\n",
    "import chromadb\n",
    "import langchain\n",
    "import openai\n",
    "from langchain.chains import LLMBashChain, LLMChain, RetrievalQA, SimpleSequentialChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "import credentials"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T07:53:42.053250Z",
     "start_time": "2023-05-08T07:53:38.278794Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "command for Jupyter Notebook or IPython, which is used to load an extension called \"watermark\" and display version information for all the installed packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.10\n",
      "IPython version      : 8.12.0\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 22.2.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 10\n",
      "Architecture: 64bit\n",
      "\n",
      "langchain: 0.0.149\n",
      "chromadb : 0.3.21\n",
      "openai   : 0.27.4\n",
      "sys      : 3.10.10 (main, Mar 21 2023, 13:41:39) [Clang 14.0.6 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions -v -m"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T07:53:43.542312Z",
     "start_time": "2023-05-08T07:53:43.504547Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add a print_response function to wrap the response of the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def print_response(response: str):\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=100)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T07:53:45.456896Z",
     "start_time": "2023-05-08T07:53:45.450708Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a new openai api key\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = getpass()\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials.OPENAI_API_KEY"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-08T07:54:51.216300Z",
     "start_time": "2023-05-08T07:54:48.761347Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# create a new chat model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-08T07:54:58.100046Z",
     "start_time": "2023-05-08T07:54:58.094245Z"
    }
   },
   "outputs": [],
   "source": [
    "chat_gpt = ChatOpenAI(temperature=0.2, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a template for the prompt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You have to come up with location to shoot (along with a 20-50 word description)\n",
    "for a new episode of the TV show \"The Office\" based on the theme.\n",
    "\n",
    "{theme_suggestion}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"theme_suggestion\"], template=template)\n",
    "\n",
    "location_chain = LLMChain(llm=chat_gpt, prompt=prompt, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:36:37.920521Z",
     "start_time": "2023-05-04T14:36:37.912270Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "You have to come up with location to shoot (along with a 20-50 word description)\n",
      "for a new episode of the TV show \"The Office\" based on the theme.\n",
      "\n",
      "Visiting Europe\n",
      "\n",
      "ANSWER:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'theme_suggestion': 'Visiting Europe',\n 'text': 'The Office crew heads to Paris, France for a company-wide conference. But when Michael gets lost in the city of love, chaos ensues as the rest of the team tries to find him before the conference begins. Will they make it in time? Tune in to find out.'}"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = location_chain(\"Visiting Europe\")\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:04:43.091628Z",
     "start_time": "2023-05-04T14:04:37.970060Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Office crew heads to Paris, France for a company-wide conference. But when Michael gets lost in\n",
      "the city of love, chaos ensues as the rest of the team tries to find him before the conference\n",
      "begins. Will they make it in time? Tune in to find out.\n"
     ]
    }
   ],
   "source": [
    "print_response(response[\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:05:29.966785Z",
     "start_time": "2023-05-04T14:05:29.964801Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sequential chains\n",
    "The next step after calling a language model is make a series of calls to a language model. This is particularly useful when you want to take the output from one call and use it as the input to another.\n",
    "\n",
    "In this notebook we will walk through some examples for how to do this, using sequential chains. Sequential chains are defined as a series of chains, called in deterministic order. There are two types of sequential chains:\n",
    "\n",
    "SimpleSequentialChain: The simplest form of sequential chains, where each step has a singular input/output, and the output of one step is the input to the next.\n",
    "\n",
    "SequentialChain: A more general form of sequential chains, allowing for multiple inputs/outputs.\n",
    "\n",
    "[Documentation](https://python.langchain.com/en/latest/modules/chains/generic/sequential_chains.html)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Generate a short dialogue between Jim and Pam\n",
    "from the TV show \"The Office\" for a new episode based on the location\n",
    "\n",
    "{location}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"location\"], template=template)\n",
    "\n",
    "conversation_chain = LLMChain(llm=chat_gpt, prompt=prompt, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:05:30.909719Z",
     "start_time": "2023-05-04T14:05:30.906908Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SimpleSequentialChain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "You have to come up with location to shoot (along with a 20-50 word description)\n",
      "for a new episode of the TV show \"The Office\" based on the theme.\n",
      "\n",
      "Visiting Europe\n",
      "\n",
      "ANSWER:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mThe Office crew heads to Paris, France for a business trip. While there, they get lost in the city of love, indulge in French cuisine, and experience cultural differences that lead to hilarious misunderstandings.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Generate a short dialogue between Jim and Pam\n",
      "from the TV show \"The Office\" for a new episode based on the location\n",
      "\n",
      "The Office crew heads to Paris, France for a business trip. While there, they get lost in the city of love, indulge in French cuisine, and experience cultural differences that lead to hilarious misunderstandings.\n",
      "\n",
      "ANSWER:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mJim: \"I can't believe we're in Paris, Pam. This is amazing!\"\n",
      "\n",
      "Pam: \"I know, right? I can't wait to try all the French food and see the Eiffel Tower.\"\n",
      "\n",
      "Jim: \"Speaking of food, do you know what escargot is?\"\n",
      "\n",
      "Pam: \"Yeah, it's snails. Why?\"\n",
      "\n",
      "Jim: \"I accidentally ordered it for lunch. I thought it was some kind of fancy pasta dish.\"\n",
      "\n",
      "Pam: \"Oh no, Jim. Did you eat it?\"\n",
      "\n",
      "Jim: \"I tried one, but it was too slimy and gross. I don't think I can eat anything else now.\"\n",
      "\n",
      "Pam: \"Well, at least you tried it. And we still have plenty of time to explore the city.\"\n",
      "\n",
      "Jim: \"Yeah, but I think we should stick together. I don't want to get lost in this maze of streets.\"\n",
      "\n",
      "Pam: \"Agreed. Let's make sure we always have each other's backs.\"\n",
      "\n",
      "Jim: \"Always, Pam. Always.\"\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "sequential_chain = SimpleSequentialChain(\n",
    "    chains=[location_chain, conversation_chain], verbose=True\n",
    ")\n",
    "response = sequential_chain.run(\"Visiting Europe\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:05:52.020015Z",
     "start_time": "2023-05-04T14:05:31.357781Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim: \"I can't believe we're in Paris, Pam. This is amazing!\"\n",
      "\n",
      "Pam: \"I know, right? I can't wait to try all the French food and see the Eiffel Tower.\"\n",
      "\n",
      "Jim: \"Speaking of food, do you know what escargot is?\"\n",
      "\n",
      "Pam: \"Yeah, it's snails. Why?\"\n",
      "\n",
      "Jim: \"I accidentally ordered it for lunch. I thought it was some kind of fancy pasta dish.\"\n",
      "\n",
      "Pam: \"Oh no, Jim. Did you eat it?\"\n",
      "\n",
      "Jim: \"I tried one, but it was too slimy and gross. I don't think I can eat anything else now.\"\n",
      "\n",
      "Pam: \"Well, at least you tried it. And we still have plenty of time to explore the city.\"\n",
      "\n",
      "Jim: \"Yeah, but I think we should stick together. I don't want to get lost in this maze of streets.\"\n",
      "\n",
      "Pam: \"Agreed. Let's make sure we always have each other's backs.\"\n",
      "\n",
      "Jim: \"Always, Pam. Always.\"\n"
     ]
    }
   ],
   "source": [
    "conversation = response\n",
    "print(conversation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:10:28.655029Z",
     "start_time": "2023-05-04T14:10:28.647439Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summarization\n",
    "\n",
    "Summarization covers three different chain types: stuff, map_reduce, and refine\n",
    "\n",
    "### Stuffing\n",
    "Stuffing is the simplest method, whereby you simply stuff all the related data into the prompt as context to pass to the language model. This is implemented in LangChain as the StuffDocumentsChain.\n",
    "\n",
    "Pros: Only makes a single call to the LLM. When generating text, the LLM has access to all the data at once.\n",
    "\n",
    "Cons: Most LLMs have a context length, and for large documents (or many documents) this will not work as it will result in a prompt larger than the context length.\n",
    "\n",
    "The main downside of this method is that it only works on smaller pieces of data. Once you are working with many pieces of data, this approach is no longer feasible. The next two approaches are designed to help deal with that.\n",
    "\n",
    "### Map Reduce\n",
    "This method involves running an initial prompt on each chunk of data (for summarization tasks, this could be a summary of that chunk; for question-answering tasks, it could be an answer based solely on that chunk). Then a different prompt is run to combine all the initial outputs. This is implemented in the LangChain as the MapReduceDocumentsChain.\n",
    "\n",
    "Pros: Can scale to larger documents (and more documents) than StuffDocumentsChain. The calls to the LLM on individual documents are independent and can therefore be parallelized.\n",
    "\n",
    "Cons: Requires many more calls to the LLM than StuffDocumentsChain. Loses some information during the final combined call.\n",
    "\n",
    "### Refine\n",
    "This method involves running an initial prompt on the first chunk of data, generating some output. For the remaining documents, that output is passed in, along with the next document, asking the LLM to refine the output based on the new document.\n",
    "\n",
    "Pros: Can pull in more relevant context, and may be less lossy than MapReduceDocumentsChain.\n",
    "\n",
    "Cons: Requires many more calls to the LLM than StuffDocumentsChain. The calls are also NOT independent, meaning they cannot be paralleled like MapReduceDocumentsChain. There is also some potential dependencies on the ordering of the documents.\n",
    "\n",
    "### Map-Rerank (not implemented for summarization)\n",
    "This method involves running an initial prompt on each chunk of data, that not only tries to complete a task but also gives a score for how certain it is in its answer. The responses are then ranked according to this score, and the highest score is returned.\n",
    "\n",
    "Pros: Similar pros as MapReduceDocumentsChain. Requires fewer calls, compared to MapReduceDocumentsChain.\n",
    "\n",
    "Cons: Cannot combine information between documents. This means it is most useful when you expect there to be a single simple answer in a single document.\n",
    "\n",
    "[Documentation](https://docs.langchain.com/docs/components/chains/index_related_chains)\n",
    "[Example](https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Write a concise bullet list summary of the conversation between Jim and Pam from the TV show \"The Office\":\n",
    "\n",
    "{text}\n",
    "\n",
    "Concise summary using markdown:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "summary_chain = load_summarize_chain(\n",
    "    chat_gpt, chain_type=\"stuff\", verbose=True, prompt=prompt\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:10:30.368831Z",
     "start_time": "2023-05-04T14:10:30.367136Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='Jim: \"I can\\'t believe we\\'re in Paris, Pam. This is amazing!\"\\n\\nPam: \"I know, right? I can\\'t wait to try all the French food and see the Eiffel Tower.\"\\n\\nJim: \"Speaking of food, do you know what escargot is?\"\\n\\nPam: \"Yeah, it\\'s snails. Why?\"\\n\\nJim: \"I accidentally ordered it for lunch. I thought it was some kind of fancy pasta dish.\"\\n\\nPam: \"Oh no, Jim. Did you eat it?\"\\n\\nJim: \"I tried one, but it was too slimy and gross. I don\\'t think I can eat anything else now.\"\\n\\nPam: \"Well, at least you tried it. And we still have plenty of time to explore the city.\"\\n\\nJim: \"Yeah, but I think we should stick together. I don\\'t want to get lost in this maze of streets.\"\\n\\nPam: \"Agreed. Let\\'s make sure we always have each other\\'s backs.\"\\n\\nJim: \"Always, Pam. Always.\"', metadata={})]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [Document(page_content=conversation)]\n",
    "docs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:10:31.256600Z",
     "start_time": "2023-05-04T14:10:31.253897Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Write a concise bullet list summary of the conversation between Jim and Pam from the TV show \"The Office\":\n",
      "\n",
      "Jim: \"I can't believe we're in Paris, Pam. This is amazing!\"\n",
      "\n",
      "Pam: \"I know, right? I can't wait to try all the French food and see the Eiffel Tower.\"\n",
      "\n",
      "Jim: \"Speaking of food, do you know what escargot is?\"\n",
      "\n",
      "Pam: \"Yeah, it's snails. Why?\"\n",
      "\n",
      "Jim: \"I accidentally ordered it for lunch. I thought it was some kind of fancy pasta dish.\"\n",
      "\n",
      "Pam: \"Oh no, Jim. Did you eat it?\"\n",
      "\n",
      "Jim: \"I tried one, but it was too slimy and gross. I don't think I can eat anything else now.\"\n",
      "\n",
      "Pam: \"Well, at least you tried it. And we still have plenty of time to explore the city.\"\n",
      "\n",
      "Jim: \"Yeah, but I think we should stick together. I don't want to get lost in this maze of streets.\"\n",
      "\n",
      "Pam: \"Agreed. Let's make sure we always have each other's backs.\"\n",
      "\n",
      "Jim: \"Always, Pam. Always.\"\n",
      "\n",
      "Concise summary using markdown:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "summary_result = summary_chain.run(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:10:48.274536Z",
     "start_time": "2023-05-04T14:10:42.295192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Jim and Pam are in Paris and excited to explore the city\n",
      "- Jim accidentally ordered escargot for lunch, thinking it was a pasta dish\n",
      "- He tried one but found it slimy and gross\n",
      "- They plan to stick together to avoid getting lost in the city\n",
      "- They agree to always have each other's backs.\n"
     ]
    }
   ],
   "source": [
    "print(summary_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:11:05.720726Z",
     "start_time": "2023-05-04T14:11:05.707883Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question answering\n",
    "\n",
    "Here we look at how to use LangChain for question answering over a list of documents. It covers four different types of chains: stuff, map_reduce, refine, map_rerank\n",
    "\n",
    "[Example](https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You have to come up with a 200-300 word script for a new episode\n",
    "of the TV show \"The Office\" based on the theme\n",
    "\n",
    "{theme_suggestion}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"theme_suggestion\"], template=template)\n",
    "\n",
    "script_chain = LLMChain(llm=chat_gpt, prompt=prompt, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:13:53.329179Z",
     "start_time": "2023-05-04T14:13:53.323309Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "You have to come up with a 200-300 word script for a new episode\n",
      "of the TV show \"The Office\" based on the theme\n",
      "\n",
      "Visiting Europe\n",
      "\n",
      "ANSWER:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "script_response = script_chain(\"Visiting Europe\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:14:42.167860Z",
     "start_time": "2023-05-04T14:13:53.919395Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: The Office Goes to Europe\n",
      "\n",
      "INT. DUNDER MIFFLIN SCRANTON OFFICE - DAY\n",
      "\n",
      "Michael Scott is sitting at his desk, scrolling through his social media feed. He stops at a picture of his ex-girlfriend, Jan, who is currently on a European vacation.\n",
      "\n",
      "MICHAEL: (to the camera) Jan is in Europe? That's it. We're going to Europe.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. CONFERENCE ROOM - DAY\n",
      "\n",
      "Michael is addressing the staff.\n",
      "\n",
      "MICHAEL: Attention, everyone. We are going to Europe! We'll be visiting our sister branches in London, Paris, and Berlin.\n",
      "\n",
      "JIM: (to the camera) I'm excited to see Europe, but I'm also a little worried about Michael's planning skills.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. AIRPORT - DAY\n",
      "\n",
      "The staff is gathered at the airport, waiting for their flight.\n",
      "\n",
      "DWIGHT: (to the camera) I've packed everything I need for survival in Europe. Including a Swiss Army knife, a map, and a book on European history.\n",
      "\n",
      "PAM: (to Jim) Do you think Michael knows we need passports to get into Europe?\n",
      "\n",
      "JIM: (shrugs) Who knows?\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. LONDON OFFICE - DAY\n",
      "\n",
      "The staff is greeted by their British counterparts, who are less than impressed with their American colleagues.\n",
      "\n",
      "BRITISH BOSS: (to Michael) I'm sorry, but we don't have time to show you around. We have work to do.\n",
      "\n",
      "MICHAEL: (to the camera) I guess the British are still a little sore about that whole revolution thing.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. PARIS OFFICE - DAY\n",
      "\n",
      "The staff is struggling with the language barrier and cultural differences.\n",
      "\n",
      "KEVIN: (to the camera) I thought French fries were supposed to be better in France, but they just taste like regular fries.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. BERLIN OFFICE - DAY\n",
      "\n",
      "The staff is surprised to find that their German counterparts are very efficient and serious.\n",
      "\n",
      "ANGELA: (to the camera) I thought Germans were supposed to be fun-loving and carefree. But these guys are all business.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. AIRPORT - DAY\n",
      "\n",
      "The staff is back at the airport, ready to head home.\n",
      "\n",
      "MICHAEL: (to the camera) Europe was great! We learned so much about our sister branches and their cultures. And we even managed to sneak in a little sightseeing.\n",
      "\n",
      "PAM: (to Jim) I can't believe we made it back without any major disasters.\n",
      "\n",
      "JIM: (smiling) Yeah, we're pretty lucky.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. DUNDER MIFFLIN SCRANTON OFFICE - DAY\n",
      "\n",
      "The staff is back at their desks, looking through their souvenirs.\n",
      "\n",
      "DWIGHT: (to the camera) I may have lost my Swiss Army knife in Paris, but I gained a new appreciation for French cheese.\n",
      "\n",
      "MICHAEL: (to the camera) I can't wait to plan our next international trip. Maybe we'll go to Asia next!\n"
     ]
    }
   ],
   "source": [
    "script = script_response[\"text\"]\n",
    "print(script)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:14:42.174056Z",
     "start_time": "2023-05-04T14:14:42.170771Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the script into chunks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_docs = [Document(page_content=script)]\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2048, chunk_overlap=32)\n",
    "texts = text_splitter.split_documents(script_docs)\n",
    "len(texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T15:06:56.893038Z",
     "start_time": "2023-05-04T15:06:56.867144Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(page_content=\"Title: The Office Goes to Europe\\n\\nINT. DUNDER MIFFLIN SCRANTON OFFICE - DAY\\n\\nMichael Scott is sitting at his desk, scrolling through his social media feed. He stops at a picture of his ex-girlfriend, Jan, who is currently on a European vacation.\\n\\nMICHAEL: (to the camera) Jan is in Europe? That's it. We're going to Europe.\\n\\nCUT TO:\\n\\nINT. CONFERENCE ROOM - DAY\\n\\nMichael is addressing the staff.\\n\\nMICHAEL: Attention, everyone. We are going to Europe! We'll be visiting our sister branches in London, Paris, and Berlin.\\n\\nJIM: (to the camera) I'm excited to see Europe, but I'm also a little worried about Michael's planning skills.\\n\\nCUT TO:\\n\\nINT. AIRPORT - DAY\\n\\nThe staff is gathered at the airport, waiting for their flight.\\n\\nDWIGHT: (to the camera) I've packed everything I need for survival in Europe. Including a Swiss Army knife, a map, and a book on European history.\\n\\nPAM: (to Jim) Do you think Michael knows we need passports to get into Europe?\\n\\nJIM: (shrugs) Who knows?\\n\\nCUT TO:\\n\\nINT. LONDON OFFICE - DAY\\n\\nThe staff is greeted by their British counterparts, who are less than impressed with their American colleagues.\\n\\nBRITISH BOSS: (to Michael) I'm sorry, but we don't have time to show you around. We have work to do.\\n\\nMICHAEL: (to the camera) I guess the British are still a little sore about that whole revolution thing.\\n\\nCUT TO:\\n\\nINT. PARIS OFFICE - DAY\\n\\nThe staff is struggling with the language barrier and cultural differences.\\n\\nKEVIN: (to the camera) I thought French fries were supposed to be better in France, but they just taste like regular fries.\\n\\nCUT TO:\\n\\nINT. BERLIN OFFICE - DAY\\n\\nThe staff is surprised to find that their German counterparts are very efficient and serious.\\n\\nANGELA: (to the camera) I thought Germans were supposed to be fun-loving and carefree. But these guys are all business.\\n\\nCUT TO:\\n\\nINT. AIRPORT - DAY\\n\\nThe staff is back at the airport, ready to head home.\", metadata={})"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:29:18.683118Z",
     "start_time": "2023-05-04T14:29:18.678840Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a database of embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:29:30.054849Z",
     "start_time": "2023-05-04T14:29:30.041267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(texts, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:29:42.318920Z",
     "start_time": "2023-05-04T14:29:41.060202Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a question answering chain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_gpt, chain_type=\"stuff\", retriever=db.as_retriever(search_kwargs={\"k\": 2}, verbose=True)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:30:24.532572Z",
     "start_time": "2023-05-04T14:30:24.526943Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'What is the location that The Office team is visiting?',\n 'result': 'The Office team is visiting their sister branches in London, Paris, and Berlin.'}"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = qa_chain(\"What is the location that The Office team is visiting?\")\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:30:28.066274Z",
     "start_time": "2023-05-04T14:30:25.347595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Office team is visiting their sister branches in London, Paris, and Berlin.\n"
     ]
    }
   ],
   "source": [
    "print_response(response[\"result\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:30:58.582006Z",
     "start_time": "2023-05-04T14:30:58.568920Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lest test if it knows that this is not in the text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no information provided in the context that suggests the client doesn't want to deal with\n",
      "Michael.\n"
     ]
    }
   ],
   "source": [
    "response = qa_chain(\"Why the client doesn't want to deal with Michael?\")\n",
    "print_response(response[\"result\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T14:31:21.529769Z",
     "start_time": "2023-05-04T14:31:18.827229Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bash Chain\n",
    "\n",
    "The BashChain is a special chain that allows you to run bash commands. It is useful for chaining together bash commands with other chains.\n",
    "[Documentation](https://python.langchain.com/en/latest/modules/chains/examples/llm_bash.html?highlight=bash%20chain)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMBashChain chain...\u001B[0m\n",
      "\n",
      "Please write a bash script that prints a single line that Michael G. Scott from \"The Office\" might say\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "```bash\n",
      "echo \"That's what she said!\"\n",
      "```\u001B[0m['```bash', 'echo \"That\\'s what she said!\"', '```']\n",
      "\n",
      "Answer: \u001B[33;1m\u001B[1;3mThat's what she said!\n",
      "\u001B[0m\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"That's what she said!\\n\""
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Please write a bash script that prints a single line that Michael G. Scott from \"The Office\" might say\n",
    "\"\"\"\n",
    "\n",
    "bash_chain = LLMBashChain(llm=OpenAI(temperature=0), verbose=True)\n",
    "\n",
    "bash_chain.run(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T15:31:52.412401Z",
     "start_time": "2023-05-04T15:31:50.071840Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
