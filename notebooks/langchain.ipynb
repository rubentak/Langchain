{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Langchain\n",
    "\n",
    "In this tutorial, we will walk through the basics of using LangChain to create a simple AI chatbot that can answer questions using OpenAI and Serpapi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:36:10.629119Z",
     "start_time": "2023-05-30T11:36:09.322285Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:36:21.666092Z",
     "start_time": "2023-05-30T11:36:21.663465Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a new openai api key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:36:30.638518Z",
     "start_time": "2023-05-30T11:36:30.634849Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up openai api key\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The temperature of a llm is a hyperparameter that controls the randomness of the output. It is a value between 0 and 1. A higher temperature will result in more random output. A lower temperature will result in more predictable output. For this tutorial, we will set the temperature to 0.9. You can play around with this yourself to see how it affects the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:36:33.975382Z",
     "start_time": "2023-05-30T11:36:33.463043Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a llm\n",
    "llm = OpenAI(temperature = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:36:39.060043Z",
     "start_time": "2023-05-30T11:36:34.539266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Ireland \n",
      "2. Germany \n",
      "3. Ukraine\n",
      "4. United States of America\n"
     ]
    }
   ],
   "source": [
    "text = \"What are 4 countries where they eat a lot of potatoes?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This works! But what if we what if we want to ask a question about a different food? We can use the prompt template class to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with prompt templates\n",
    "\n",
    "### A prompt template is a string that contains variables that can be filled in with different values. For example, you could have a prompt template that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:36:39.064197Z",
     "start_time": "2023-05-30T11:36:39.062108Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:51:21.665992Z",
     "start_time": "2023-05-04T07:51:21.661148Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 4 countries where they eat a lot of {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:51:22.267425Z",
     "start_time": "2023-05-04T07:51:22.259980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are 4 countries where they eat a lot of potatoes?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(food=\"potatoes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:51:25.790414Z",
     "start_time": "2023-05-04T07:51:23.070055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Ireland \n",
      "2. Germany \n",
      "3. Russia \n",
      "4. Poland\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"potatoes\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the answer is different from the previous one. This is because of the randomness of the llm. If we want to get the same answer every time, we can set the seed of the llm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:52:37.534975Z",
     "start_time": "2023-05-04T07:52:33.797048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. China \n",
      "2. India \n",
      "3. Indonesia \n",
      "4. Japan\n"
     ]
    }
   ],
   "source": [
    "print(llm(prompt.format(food=\"rice\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaining\n",
    "\n",
    "### Here, we combine LLMs and prompts in multistep workflows using the prompt template class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:36:52.678573Z",
     "start_time": "2023-05-30T11:36:52.672937Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:52:42.738643Z",
     "start_time": "2023-05-04T07:52:42.733814Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"food\"],\n",
    "    template=\"What are 4 countries where they eat a lot of {food}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:52:44.089168Z",
     "start_time": "2023-05-04T07:52:44.083051Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:52:47.473090Z",
     "start_time": "2023-05-04T07:52:44.458688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Ireland\n",
      "2. United States\n",
      "3. Germany\n",
      "4. United Kingdom\n",
      "\n",
      "\n",
      "1. China\n",
      "2. Japan\n",
      "3. India\n",
      "4. Indonesia\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"potatoes\"))\n",
    "print(chain.run(\"rice\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents: Dynamically call chains based on user input\n",
    "\n",
    "SerpApi is a search engine results page (SERP) scraping and parsing API that allows developers to retrieve and analyze data from various search engines, including Google, Bing, Yahoo, and more.\n",
    "\n",
    "\n",
    "To use SerpApi in Python, you will need to install the SerpApi Python module using pip. An API key can be created here:\n",
    "\n",
    "[Serpapi key](https://serpapi.com/users/sign_up)\n",
    "\n",
    "[Serpapi documentation](https://python.langchain.com/en/latest/modules/agents/tools/examples/serpapi.html)\n",
    "\n",
    "In the next part, we are going to combine OpenAI with SerpApi to create a chatbot that can answer questions with internet search results.\n",
    "\n",
    "[Agent langchain documentation](https://python.langchain.com/en/latest/modules/agents.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-25T19:11:54.670645Z",
     "start_time": "2023-04-25T19:11:51.130043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in /Users/erictak/miniconda3/lib/python3.10/site-packages (2.4.2)\r\n",
      "Requirement already satisfied: requests in /Users/erictak/miniconda3/lib/python3.10/site-packages (from google-search-results) (2.28.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erictak/miniconda3/lib/python3.10/site-packages (from requests->google-search-results) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/erictak/miniconda3/lib/python3.10/site-packages (from requests->google-search-results) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/erictak/miniconda3/lib/python3.10/site-packages (from requests->google-search-results) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/erictak/miniconda3/lib/python3.10/site-packages (from requests->google-search-results) (1.26.15)\r\n"
     ]
    }
   ],
   "source": [
    "# Install serpapi\n",
    "#!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:37:01.808465Z",
     "start_time": "2023-05-30T11:37:01.802253Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:37:02.363567Z",
     "start_time": "2023-05-30T11:37:02.359360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools are functions that agents can use to interact with the world. These tools can be generic utilities (e.g. search), other chains, or even other agents.\n",
    "Here we use the SerpApi and llm-math tools. We will use the SerpApi tool to search the internet for answers to our questions. We will use the llm-math tool to answer math questions.\n",
    "\n",
    "[Tools documentation](https://python.langchain.com/en/latest/modules/agents/tools/getting_started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:37:03.873494Z",
     "start_time": "2023-05-30T11:37:03.864545Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load in some tools to use\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"...\"\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's initialize an agent with:\n",
    " 1. The tools\n",
    " 2. The language model\n",
    " 3. The type of agent we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:37:12.060731Z",
     "start_time": "2023-05-30T11:37:12.058246Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the agent, I have chosen the zero-shot-react-description agent. This agent uses the ReAct framework to determine which tool to use based solely on the tool’s description. Any number of tools can be provided. This agent requires that a description is provided for each tool.\n",
    "\n",
    "[Agent types](https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html)\n",
    "\n",
    "By setting verbose=True, we can see the agent's internal state as it processes the input.\n",
    "\n",
    "Other agent types could also be chosen\n",
    "\n",
    "Now, let us ask our agent a question for which it will use the Serpapi tool to search the internet for an answer and need to calculate the answer using the llm-math tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T07:53:41.299371Z",
     "start_time": "2023-05-04T07:53:16.761842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m I need to find out Obama's height and then use a calculator to figure out how many cans of coke I need.\n",
      "Action: Search\n",
      "Action Input: Obama's height\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m6′ 2″\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I need to convert this to centimeters and then use a calculator to figure out how many cans of coke I need.\n",
      "Action: Calculator\n",
      "Action Input: 6 feet 2 inches in centimeters\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mAnswer: 187.96\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the number of centimeters and can use a calculator to figure out how many cans of coke I need.\n",
      "Action: Calculator\n",
      "Action Input: 187.96 cm divided by 12 cm (the height of a can of coke)\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mAnswer: 15.663333333333334\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3m I now know the final answer\n",
      "Final Answer: 15.66 cans of coke can be stacked to reach Obama's height of 6 feet 2 inches.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"15.66 cans of coke can be stacked to reach Obama's height of 6 feet 2 inches.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is the hight of Obama? And how many cans of coke can you stack to reach that height?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory: Add state to chains and agents\n",
    "\n",
    "By adding memory to our agents, we can make them more dynamic and interactive. We can have a conversation and the agent will remember what we said and use that information to answer our questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T12:29:08.500700Z",
     "start_time": "2023-05-30T12:29:08.493903Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T12:29:08.959006Z",
     "start_time": "2023-05-30T12:29:08.954605Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T12:29:21.891332Z",
     "start_time": "2023-05-30T12:29:09.413977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi how are you doing!\n",
      "AI:\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" Hi there! I'm doing great, thanks for asking. How about you?\""
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi how are you doing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T12:29:40.858247Z",
     "start_time": "2023-05-30T12:29:27.121060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi how are you doing!\n",
      "AI:  Hi there! I'm doing great, thanks for asking. How about you?\n",
      "Human: I want a list of the top 20 Brazilian data consultancy companies\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Sure, I can provide you with a list of the top 20 Brazilian data consultancy companies. Here they are: 1. DataLab, 2. DataMiner, 3. DataMind, 4. DataViz, 5. DataVault, 6. DataTrust, 7. DataCore, 8. DataFlux, 9. DataVantage, 10. DataFlex, 11. DataVista, 12. DataLogic, 13. DataMentor, 14. DataVista, 15. DataVault, 16. DataMind, 17. DataFlex, 18. DataCore, 19. DataViz, 20. DataLab. Is there anything else I can help you with?'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I want a list of the top 20 Brazilian data consultancy companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T11:40:13.169078Z",
     "start_time": "2023-05-30T11:39:48.513238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi how are you doing!\n",
      "AI:  Hi there! I'm doing great, thanks for asking. How about you?\n",
      "Human: I want a list of the top data consultancy companies in the Netherlands\n",
      "AI:  Sure, I can provide you with a list of the top data consultancy companies in the Netherlands. The top five are: Accenture, Capgemini, Deloitte, KPMG, and PwC. Is there anything else I can help you with?\n",
      "Human: I want a list of the top 20 data consultancy companies in the Netherlands\n",
      "AI:  Sure, I can provide you with a list of the top 20 data consultancy companies in the Netherlands. The top 20 are: Accenture, Capgemini, Deloitte, KPMG, PwC, Atos, CGI, EY, IBM, Infosys, NTT Data, Orange Business Services, Sopra Steria, Tata Consultancy Services, Tech Mahindra, Wipro, Cognizant, Fujitsu, HCL Technologies, and Mindtree. Is there anything else I can help you with?\n",
      "Human: I want a list of all these companies and their websites\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Sure, I can provide you with a list of the top 20 data consultancy companies in the Netherlands and their websites. The list is as follows: \\n\\nAccenture: www.accenture.com\\nCapgemini: www.capgemini.com\\nDeloitte: www.deloitte.com\\nKPMG: www.kpmg.com\\nPwC: www.pwc.com\\nAtos: www.atos.net\\nCGI: www.cgi.com\\nEY: www.ey.com\\nIBM: www.ibm.com\\nInfosys: www.infosys.com\\nNTT Data: www.nttdata.com\\nOrange Business Services: www.orange-business.com\\nSopra Steria: www.soprasteria.com\\nTata Consultancy Services: www.tcs.com\\nTech Mahindra: www.techmahindra.com\\nWipro: www.wipro.com\\nCognizant: www.cognizant.com\\nFujitsu: www.fujitsu.com\\nHCL Technologies: www.hcltech.com'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I want a list of all these companies and their websites\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue the conversation yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T12:30:57.807518Z",
     "start_time": "2023-05-30T12:30:26.043999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi how are you doing!\n",
      "AI:  Hi there! I'm doing great, thanks for asking. How about you?\n",
      "Human: I want a list of the top 20 Brazilian data consultancy companies\n",
      "AI:  Sure, I can provide you with a list of the top 20 Brazilian data consultancy companies. Here they are: 1. DataLab, 2. DataMiner, 3. DataMind, 4. DataViz, 5. DataVault, 6. DataTrust, 7. DataCore, 8. DataFlux, 9. DataVantage, 10. DataFlex, 11. DataVista, 12. DataLogic, 13. DataMentor, 14. DataVista, 15. DataVault, 16. DataMind, 17. DataFlex, 18. DataCore, 19. DataViz, 20. DataLab. Is there anything else I can help you with?\n",
      "Human: Print this list op companies and their websites in the way 'company name' - 'website'\n",
      "AI:\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      " Sure, I can do that. Here is the list of the top 20 Brazilian data consultancy companies and their websites: DataLab - www.datalab.com.br, DataMiner - www.dataminer.com.br, DataMind - www.datamind.com.br, DataViz - www.dataviz.com.br, DataVault - www.datavault.com.br, DataTrust - www.datatrust.com.br, DataCore - www.datacore.com.br, DataFlux - www.dataflux.com.br, DataVantage - www.datavantage.com.br, DataFlex - www.dataflex.com.br, DataVista - www.datavista.com.br, DataLogic - www.datalogic.com.br, DataMentor - www.datamentor.com.br, DataVista - www.datavista.com.br, DataVault - www.datavault.com.br, DataMind - www.datamind.com.br, DataFlex - www.dataflex.com.br, Data\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"Print this list op companies and their websites in the way 'company name' - 'website'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi how are you doing!\n",
      "AI:  Hi there! I'm doing great, thanks for asking. How about you?\n",
      "Human: I want a list of the top 20 Brazilian data consultancy companies\n",
      "AI:  Sure, I can provide you with a list of the top 20 Brazilian data consultancy companies. Here they are: 1. DataLab, 2. DataMiner, 3. DataMind, 4. DataViz, 5. DataVault, 6. DataTrust, 7. DataCore, 8. DataFlux, 9. DataVantage, 10. DataFlex, 11. DataVista, 12. DataLogic, 13. DataMentor, 14. DataVista, 15. DataVault, 16. DataMind, 17. DataFlex, 18. DataCore, 19. DataViz, 20. DataLab. Is there anything else I can help you with?\n",
      "Human: Print this list op companies and their websites in the way 'company name' - 'website'\n",
      "AI:  Sure, I can do that. Here is the list of the top 20 Brazilian data consultancy companies and their websites: DataLab - www.datalab.com.br, DataMiner - www.dataminer.com.br, DataMind - www.datamind.com.br, DataViz - www.dataviz.com.br, DataVault - www.datavault.com.br, DataTrust - www.datatrust.com.br, DataCore - www.datacore.com.br, DataFlux - www.dataflux.com.br, DataVantage - www.datavantage.com.br, DataFlex - www.dataflex.com.br, DataVista - www.datavista.com.br, DataLogic - www.datalogic.com.br, DataMentor - www.datamentor.com.br, DataVista - www.datavista.com.br, DataVault - www.datavault.com.br, DataMind - www.datamind.com.br, DataFlex - www.dataflex.com.br, Data\n",
      "Human: What are websites where i can see all the top data consultancy companies in Brazil?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      " Sure, I can provide you with some websites where you can find the top data consultancy companies in Brazil. Here are some of the most popular websites: DataViz, DataMind, DataTrust, DataCore, DataFlux, DataVantage, and DataFlex. You can also find a comprehensive list of data consultancy companies in Brazil on websites such as DataVista, DataLogic, and DataMentor.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.predict(input=\"What are websites where i can see all the top data consultancy companies in Brazil?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-30T12:38:04.125900Z",
     "start_time": "2023-05-30T12:37:53.589888Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the end of the tutorial. We hope you enjoyed it!\n",
    "\n",
    "Follow me on Github and Medium for more content:\n",
    "\n",
    "- [Github](https://github.com/rubentak)\n",
    "- [Medium](https://medium.com/@rubentak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
