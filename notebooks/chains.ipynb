{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LangChain Chains\n",
    "\n",
    "in this notebook we will take a look at different langchain chains"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# install the packages\n",
    "!pip install -Uqqq pip --progress-bar off\n",
    "!pip install -qqq langchain==0.0.149 --progress-bar off\n",
    "!pip install -qqq openai==0.27.4 --progress-bar off\n",
    "!pip install -qqq tiktoken==0.3.3 --progress-bar off\n",
    "!pip install -qqq watermark==2.3.1 --progress-bar off\n",
    "!pip install -qqq chromadb==0.3.21 --progress-bar off"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:18:50.880652Z",
     "end_time": "2023-05-15T12:19:17.112307Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import os\n",
    "import textwrap\n",
    "from getpass import getpass\n",
    "import chromadb\n",
    "import langchain\n",
    "import openai\n",
    "from langchain.chains import LLMBashChain, LLMChain, RetrievalQA, SimpleSequentialChain\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "import credentials"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:17.111791Z",
     "end_time": "2023-05-15T12:19:21.110437Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "command for Jupyter Notebook or IPython, which is used to load an extension called \"watermark\" and display version information for all the installed packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.10\n",
      "IPython version      : 8.12.0\n",
      "\n",
      "Compiler    : Clang 14.0.6 \n",
      "OS          : Darwin\n",
      "Release     : 22.2.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 10\n",
      "Architecture: 64bit\n",
      "\n",
      "langchain: 0.0.149\n",
      "openai   : 0.27.4\n",
      "sys      : 3.10.10 (main, Mar 21 2023, 13:41:39) [Clang 14.0.6 ]\n",
      "chromadb : 0.3.21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark --iversions -v -m"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:25.807982Z",
     "end_time": "2023-05-15T12:19:25.846670Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add a print_response function to wrap the response of the models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def print_response(response: str):\n",
    "    print(\"\\n\".join(textwrap.wrap(response, width=100)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:27.130425Z",
     "end_time": "2023-05-15T12:19:27.140915Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a new openai api key\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = getpass()\n",
    "os.environ[\"OPENAI_API_KEY\"] = credentials.OPENAI_API_KEY"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:27.958916Z",
     "end_time": "2023-05-15T12:19:34.140795Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a new chat model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:36.515176Z",
     "end_time": "2023-05-15T12:19:36.519258Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0.3, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a template for the prompt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You have to come up with location to shoot (along with a 20-50 word description)\n",
    "for a new episode of the TV show \"The Office\" based on the theme.\n",
    "\n",
    "{theme_suggestion}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"theme_suggestion\"], template=template)\n",
    "\n",
    "location_chain = LLMChain(llm=model, prompt=prompt, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:37.378075Z",
     "end_time": "2023-05-15T12:19:37.384846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "You have to come up with location to shoot (along with a 20-50 word description)\n",
      "for a new episode of the TV show \"The Office\" based on the theme.\n",
      "\n",
      "Visiting Europe\n",
      "\n",
      "ANSWER:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'theme_suggestion': 'Visiting Europe',\n 'text': 'The Office crew heads to Paris, France for a company retreat. While there, they struggle with language barriers, cultural differences, and a surprise visit from a former employee. Will they be able to bond and come together as a team in the City of Love?'}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = location_chain(\"Visiting Europe\")\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:38.001174Z",
     "end_time": "2023-05-15T12:19:43.487915Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Office crew heads to Paris, France for a company retreat. While there, they struggle with\n",
      "language barriers, cultural differences, and a surprise visit from a former employee. Will they be\n",
      "able to bond and come together as a team in the City of Love?\n"
     ]
    }
   ],
   "source": [
    "print_response(response[\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:44.684688Z",
     "end_time": "2023-05-15T12:19:44.694076Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sequential chains\n",
    "\n",
    "\n",
    "[Documentation](https://python.langchain.com/en/latest/modules/chains/generic/sequential_chains.html)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Generate a short dialogue between Jim and Pam\n",
    "from the TV show \"The Office\" for a new episode based on the location\n",
    "\n",
    "{location}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"location\"], template=template)\n",
    "\n",
    "conversation_chain = LLMChain(llm=model, prompt=prompt, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:45.840574Z",
     "end_time": "2023-05-15T12:19:45.844871Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SimpleSequentialChain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new SimpleSequentialChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "You have to come up with location to shoot (along with a 20-50 word description)\n",
      "for a new episode of the TV show \"The Office\" based on the theme.\n",
      "\n",
      "Visiting Europe\n",
      "\n",
      "ANSWER:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[36;1m\u001B[1;3mThe Office crew heads to Paris for a business trip, but things take a romantic turn when Jim and Pam get lost in the city of love. Meanwhile, Dwight tries to navigate the French language and culture with hilarious results.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Generate a short dialogue between Jim and Pam\n",
      "from the TV show \"The Office\" for a new episode based on the location\n",
      "\n",
      "The Office crew heads to Paris for a business trip, but things take a romantic turn when Jim and Pam get lost in the city of love. Meanwhile, Dwight tries to navigate the French language and culture with hilarious results.\n",
      "\n",
      "ANSWER:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[33;1m\u001B[1;3mJim: \"I can't believe we got lost in Paris, of all places.\"\n",
      "\n",
      "Pam: \"I know, right? But I have to admit, it's kind of romantic wandering around these streets with you.\"\n",
      "\n",
      "Jim: \"Yeah, it's like we're in our own little movie.\"\n",
      "\n",
      "Pam: \"Speaking of movies, we should find a cute little cafe and have some croissants and coffee.\"\n",
      "\n",
      "Jim: \"Sounds perfect. But first, let's take a selfie in front of the Eiffel Tower.\"\n",
      "\n",
      "Pam: \"Yes! And then we can send it to Dwight and Michael to make them jealous.\"\n",
      "\n",
      "Jim: \"Ha! They're probably struggling to order food in French right now.\"\n",
      "\n",
      "Pam: \"Well, at least we have each other to navigate this city with.\"\n",
      "\n",
      "Jim: \"Always, Pam. Always.\"\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "sequential_chain = SimpleSequentialChain(\n",
    "    chains=[location_chain, conversation_chain], verbose=True\n",
    ")\n",
    "response = sequential_chain.run(\"Visiting Europe\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:19:46.918422Z",
     "end_time": "2023-05-15T12:20:09.152045Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim: \"I can't believe we got lost in Paris, of all places.\"\n",
      "\n",
      "Pam: \"I know, right? But I have to admit, it's kind of romantic wandering around these streets with you.\"\n",
      "\n",
      "Jim: \"Yeah, it's like we're in our own little movie.\"\n",
      "\n",
      "Pam: \"Speaking of movies, we should find a cute little cafe and have some croissants and coffee.\"\n",
      "\n",
      "Jim: \"Sounds perfect. But first, let's take a selfie in front of the Eiffel Tower.\"\n",
      "\n",
      "Pam: \"Yes! And then we can send it to Dwight and Michael to make them jealous.\"\n",
      "\n",
      "Jim: \"Ha! They're probably struggling to order food in French right now.\"\n",
      "\n",
      "Pam: \"Well, at least we have each other to navigate this city with.\"\n",
      "\n",
      "Jim: \"Always, Pam. Always.\"\n"
     ]
    }
   ],
   "source": [
    "conversation = response\n",
    "print(conversation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:20:12.162182Z",
     "end_time": "2023-05-15T12:20:12.174800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summarization\n",
    "\n",
    "There are four different chain types: stuff, map_reduce, refine and map-rerank. Each of these is described in more detail below.\n",
    "\n",
    "\n",
    "### Stuffing\n",
    "Stuffing is the simplest method, whereby you simply stuff all the related data into the prompt as context to pass to the language model. This is implemented in LangChain as the StuffDocumentsChain.\n",
    "\n",
    "Pros: Only makes a single call to the LLM. When generating text, the LLM has access to all the data at once.\n",
    "\n",
    "Cons: Most LLMs have a context length, and for large documents (or many documents) this will not work as it will result in a prompt larger than the context length.\n",
    "\n",
    "The main downside of this method is that it only works on smaller pieces of data. Once you are working with many pieces of data, this approach is no longer feasible. The next two approaches are designed to help deal with that.\n",
    "\n",
    "\n",
    "### Map Reduce\n",
    "This method involves running an initial prompt on each chunk of data (for summarization tasks, this could be a summary of that chunk; for question-answering tasks, it could be an answer based solely on that chunk). Then a different prompt is run to combine all the initial outputs. This is implemented in the LangChain as the MapReduceDocumentsChain.\n",
    "\n",
    "Pros: Can scale to larger documents (and more documents) than StuffDocumentsChain. The calls to the LLM on individual documents are independent and can therefore be parallelized.\n",
    "\n",
    "Cons: Requires many more calls to the LLM than StuffDocumentsChain. Loses some information during the final combined call.\n",
    "\n",
    "\n",
    "### Refine\n",
    "This method involves running an initial prompt on the first chunk of data, generating some output. For the remaining documents, that output is passed in, along with the next document, asking the LLM to refine the output based on the new document.\n",
    "\n",
    "Pros: Can pull in more relevant context, and may be less lossy than MapReduceDocumentsChain.\n",
    "\n",
    "Cons: Requires many more calls to the LLM than StuffDocumentsChain. The calls are also NOT independent, meaning they cannot be paralleled like MapReduceDocumentsChain. There is also some potential dependencies on the ordering of the documents.\n",
    "\n",
    "\n",
    "### Map-Rerank (not implemented for summarization)\n",
    "This method involves running an initial prompt on each chunk of data, that not only tries to complete a task but also gives a score for how certain it is in its answer. The responses are then ranked according to this score, and the highest score is returned.\n",
    "\n",
    "Pros: Similar pros as MapReduceDocumentsChain. Requires fewer calls, compared to MapReduceDocumentsChain.\n",
    "\n",
    "Cons: Cannot combine information between documents. This means it is most useful when you expect there to be a single simple answer in a single document.\n",
    "\n",
    "[Documentation](https://docs.langchain.com/docs/components/chains/index_related_chains)\n",
    "[Example](https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Write a concise bullet list summary of the conversation between Jim and Pam from the TV show \"The Office\":\n",
    "\n",
    "{text}\n",
    "\n",
    "Concise summary using markdown:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "summary_chain = load_summarize_chain(\n",
    "    model, chain_type=\"stuff\", verbose=True, prompt=prompt\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:20:15.725018Z",
     "end_time": "2023-05-15T12:20:15.729853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[Document(page_content='Jim: \"I can\\'t believe we got lost in Paris, of all places.\"\\n\\nPam: \"I know, right? But I have to admit, it\\'s kind of romantic wandering around these streets with you.\"\\n\\nJim: \"Yeah, it\\'s like we\\'re in our own little movie.\"\\n\\nPam: \"Speaking of movies, we should find a cute little cafe and have some croissants and coffee.\"\\n\\nJim: \"Sounds perfect. But first, let\\'s take a selfie in front of the Eiffel Tower.\"\\n\\nPam: \"Yes! And then we can send it to Dwight and Michael to make them jealous.\"\\n\\nJim: \"Ha! They\\'re probably struggling to order food in French right now.\"\\n\\nPam: \"Well, at least we have each other to navigate this city with.\"\\n\\nJim: \"Always, Pam. Always.\"', metadata={})]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [Document(page_content=conversation)]\n",
    "docs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:20:16.460643Z",
     "end_time": "2023-05-15T12:20:16.464584Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Write a concise bullet list summary of the conversation between Jim and Pam from the TV show \"The Office\":\n",
      "\n",
      "Jim: \"I can't believe we got lost in Paris, of all places.\"\n",
      "\n",
      "Pam: \"I know, right? But I have to admit, it's kind of romantic wandering around these streets with you.\"\n",
      "\n",
      "Jim: \"Yeah, it's like we're in our own little movie.\"\n",
      "\n",
      "Pam: \"Speaking of movies, we should find a cute little cafe and have some croissants and coffee.\"\n",
      "\n",
      "Jim: \"Sounds perfect. But first, let's take a selfie in front of the Eiffel Tower.\"\n",
      "\n",
      "Pam: \"Yes! And then we can send it to Dwight and Michael to make them jealous.\"\n",
      "\n",
      "Jim: \"Ha! They're probably struggling to order food in French right now.\"\n",
      "\n",
      "Pam: \"Well, at least we have each other to navigate this city with.\"\n",
      "\n",
      "Jim: \"Always, Pam. Always.\"\n",
      "\n",
      "Concise summary using markdown:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "summary_result = summary_chain.run(docs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:20:17.657879Z",
     "end_time": "2023-05-15T12:20:29.138814Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Jim and Pam got lost in Paris.\n",
      "- They find it romantic to wander around the streets together.\n",
      "- They plan to find a cute cafe and have croissants and coffee.\n",
      "- They want to take a selfie in front of the Eiffel Tower and send it to Dwight and Michael to make them jealous.\n",
      "- They are grateful to have each other to navigate the city with.\n"
     ]
    }
   ],
   "source": [
    "print(summary_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:20:31.856412Z",
     "end_time": "2023-05-15T12:20:31.865826Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Question answering\n",
    "\n",
    "Here we look at how to use LangChain for question answering over a list of documents. It covers four different types of chains: stuff, map_reduce, refine, map_rerank\n",
    "\n",
    "[Example](https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You have to come up with a 200-300 word script for a new episode\n",
    "of the TV show \"The Office\" based on the theme\n",
    "\n",
    "{theme_suggestion}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"theme_suggestion\"], template=template)\n",
    "\n",
    "script_chain = LLMChain(llm=model, prompt=prompt, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:20:33.722925Z",
     "end_time": "2023-05-15T12:20:33.728311Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "You have to come up with a 200-300 word script for a new episode\n",
      "of the TV show \"The Office\" based on the theme\n",
      "\n",
      "Going to the moon\n",
      "\n",
      "ANSWER:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "script_response = script_chain(\"Going to the moon\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:24:06.552617Z",
     "end_time": "2023-05-15T12:25:02.920288Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FADE IN:\n",
      "\n",
      "INT. DUNDER MIFFLIN SCRANTON - DAY\n",
      "\n",
      "The employees of Dunder Mifflin are gathered in the conference room for a meeting. Michael Scott is standing at the front of the room, holding a toy rocket ship.\n",
      "\n",
      "MICHAEL: Good morning, everyone! Today, we’re going to talk about the moon.\n",
      "\n",
      "JIM: (whispering to Pam) Is he serious?\n",
      "\n",
      "PAM: (whispering back) I don’t know, but I’m afraid to ask.\n",
      "\n",
      "MICHAEL: As you all know, NASA is planning a mission to the moon in a few years. And I’ve been thinking, why should they have all the fun?\n",
      "\n",
      "DWIGHT: (excitedly) Are you suggesting we go to the moon, Michael?\n",
      "\n",
      "MICHAEL: (nodding) Yes, Dwight. I am.\n",
      "\n",
      "JIM: (sarcastically) Oh, great. Another one of Michael’s brilliant ideas.\n",
      "\n",
      "MICHAEL: (ignoring Jim) I’ve already contacted a space travel agency and they’ve agreed to take us to the moon.\n",
      "\n",
      "PAM: (concerned) Michael, I don’t think that’s a good idea. Going to the moon is dangerous.\n",
      "\n",
      "MICHAEL: (defensive) Pam, I’m not going to let a little thing like danger stop us from achieving our dreams.\n",
      "\n",
      "The employees exchange worried glances.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. SPACE TRAVEL AGENCY - DAY\n",
      "\n",
      "Michael, Dwight, Jim, and Pam are standing in front of a large rocket ship.\n",
      "\n",
      "MICHAEL: (excitedly) This is it, guys. Our ticket to the moon.\n",
      "\n",
      "JIM: (sarcastically) Yay.\n",
      "\n",
      "PAM: (nervously) Michael, are you sure about this?\n",
      "\n",
      "MICHAEL: (confidently) Absolutely, Pam. Trust me, this is going to be the adventure of a lifetime.\n",
      "\n",
      "The employees reluctantly board the rocket ship.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. ROCKET SHIP - DAY\n",
      "\n",
      "The employees are strapped into their seats, looking nervous.\n",
      "\n",
      "MICHAEL: (over the intercom) Attention, everyone. We are about to take off. Please fasten your seatbelts and prepare for liftoff.\n",
      "\n",
      "The rocket ship shakes and rumbles as it takes off.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. MOON - DAY\n",
      "\n",
      "The employees are standing on the surface of the moon, wearing space suits.\n",
      "\n",
      "JIM: (in awe) Wow. We’re actually on the moon.\n",
      "\n",
      "DWIGHT: (excitedly) This is amazing. I can’t wait to explore.\n",
      "\n",
      "PAM: (worriedly) Michael, we need to get back to Earth. We can’t stay here forever.\n",
      "\n",
      "MICHAEL: (disappointed) Fine. Let’s go back.\n",
      "\n",
      "The employees board the rocket ship and take off.\n",
      "\n",
      "CUT TO:\n",
      "\n",
      "INT. DUNDER MIFFLIN SCRANTON - DAY\n",
      "\n",
      "The employees are back in the conference room, looking exhausted.\n",
      "\n",
      "MICHAEL: (smiling) Well, that was quite an adventure, wasn’t it?\n",
      "\n",
      "JIM: (sarcastically) Yeah, Michael. It was a blast.\n",
      "\n",
      "PAM: (smiling) I have to admit, it was pretty cool.\n",
      "\n",
      "DWIGHT: (excitedly) Can we go back to the moon someday?\n",
      "\n",
      "MICHAEL: (smiling) Who knows, Dwight. Maybe we will.\n",
      "\n",
      "FADE OUT.\n"
     ]
    }
   ],
   "source": [
    "script = script_response[\"text\"]\n",
    "print(script)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:25:23.104278Z",
     "end_time": "2023-05-15T12:25:23.111993Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the script into chunks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script_docs = [Document(page_content=script)]\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2048, chunk_overlap=32)\n",
    "texts = text_splitter.split_documents(script_docs)\n",
    "len(texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:26:41.515984Z",
     "end_time": "2023-05-15T12:26:41.519878Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(page_content='FADE IN:\\n\\nINT. DUNDER MIFFLIN SCRANTON - DAY\\n\\nThe employees of Dunder Mifflin are gathered in the conference room for a meeting. Michael Scott is standing at the front of the room, holding a toy rocket ship.\\n\\nMICHAEL: Good morning, everyone! Today, we’re going to talk about the moon.\\n\\nJIM: (whispering to Pam) Is he serious?\\n\\nPAM: (whispering back) I don’t know, but I’m afraid to ask.\\n\\nMICHAEL: As you all know, NASA is planning a mission to the moon in a few years. And I’ve been thinking, why should they have all the fun?\\n\\nDWIGHT: (excitedly) Are you suggesting we go to the moon, Michael?\\n\\nMICHAEL: (nodding) Yes, Dwight. I am.\\n\\nJIM: (sarcastically) Oh, great. Another one of Michael’s brilliant ideas.\\n\\nMICHAEL: (ignoring Jim) I’ve already contacted a space travel agency and they’ve agreed to take us to the moon.\\n\\nPAM: (concerned) Michael, I don’t think that’s a good idea. Going to the moon is dangerous.\\n\\nMICHAEL: (defensive) Pam, I’m not going to let a little thing like danger stop us from achieving our dreams.\\n\\nThe employees exchange worried glances.\\n\\nCUT TO:\\n\\nINT. SPACE TRAVEL AGENCY - DAY\\n\\nMichael, Dwight, Jim, and Pam are standing in front of a large rocket ship.\\n\\nMICHAEL: (excitedly) This is it, guys. Our ticket to the moon.\\n\\nJIM: (sarcastically) Yay.\\n\\nPAM: (nervously) Michael, are you sure about this?\\n\\nMICHAEL: (confidently) Absolutely, Pam. Trust me, this is going to be the adventure of a lifetime.\\n\\nThe employees reluctantly board the rocket ship.\\n\\nCUT TO:\\n\\nINT. ROCKET SHIP - DAY\\n\\nThe employees are strapped into their seats, looking nervous.\\n\\nMICHAEL: (over the intercom) Attention, everyone. We are about to take off. Please fasten your seatbelts and prepare for liftoff.\\n\\nThe rocket ship shakes and rumbles as it takes off.\\n\\nCUT TO:\\n\\nINT. MOON - DAY\\n\\nThe employees are standing on the surface of the moon, wearing space suits.\\n\\nJIM: (in awe) Wow. We’re actually on the moon.\\n\\nDWIGHT: (excitedly) This is amazing. I can’t wait to explore.', metadata={})"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:26:42.404655Z",
     "end_time": "2023-05-15T12:26:42.409217Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a database of embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:26:44.625644Z",
     "end_time": "2023-05-15T12:26:44.631084Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "db = Chroma.from_documents(texts, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:26:45.334841Z",
     "end_time": "2023-05-15T12:26:48.566773Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a question answering chain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=model, chain_type=\"stuff\", retriever=db.as_retriever(search_kwargs={\"k\": 2}, verbose=True)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:26:50.466600Z",
     "end_time": "2023-05-15T12:26:50.470999Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'What is the place that The Office team is visiting?',\n 'result': 'The Office team is visiting the moon.'}"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = qa_chain(\"What is the place that The Office team is visiting?\")\n",
    "response"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:26:51.641574Z",
     "end_time": "2023-05-15T12:26:53.330807Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Office team is visiting the moon.\n"
     ]
    }
   ],
   "source": [
    "print_response(response[\"result\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:26:59.189488Z",
     "end_time": "2023-05-15T12:26:59.195372Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lets test if it knows that this is not in the text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no information provided in the context that suggests the client doesn't want to deal with\n",
      "Michael.\n"
     ]
    }
   ],
   "source": [
    "response = qa_chain(\"Why the client doesn't want to deal with Michael?\")\n",
    "print_response(response[\"result\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:27:26.246452Z",
     "end_time": "2023-05-15T12:27:30.268906Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bash Chain\n",
    "\n",
    "The BashChain is a special chain that allows you to run bash commands. It is useful for chaining together bash commands with other chains.\n",
    "[Documentation](https://python.langchain.com/en/latest/modules/chains/examples/llm_bash.html?highlight=bash%20chain)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMBashChain chain...\u001B[0m\n",
      "\n",
      "Please write a bash script that prints a single line that Michael G. Scott from \"The Office\" might say\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "```bash\n",
      "echo \"That's what she said!\"\n",
      "```\u001B[0m['```bash', 'echo \"That\\'s what she said!\"', '```']\n",
      "\n",
      "Answer: \u001B[33;1m\u001B[1;3mThat's what she said!\n",
      "\u001B[0m\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"That's what she said!\\n\""
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Please write a bash script that prints a single line that Michael G. Scott from \"The Office\" might say\n",
    "\"\"\"\n",
    "\n",
    "bash_chain = LLMBashChain(llm=OpenAI(temperature=0), verbose=True)\n",
    "\n",
    "bash_chain.run(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-15T12:27:40.223294Z",
     "end_time": "2023-05-15T12:27:44.388835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
