{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using langchain to extract information of a textfile\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:27:54.147198Z",
     "end_time": "2023-05-23T15:27:54.149785Z"
    }
   },
   "outputs": [],
   "source": [
    "# # import libraries\n",
    "import os\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#create a new openai api key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:27:54.572890Z",
     "end_time": "2023-05-23T15:27:54.575318Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# set up openai api key\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:27:55.834529Z",
     "end_time": "2023-05-23T15:27:55.837839Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('../data/notebook.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:27:56.535470Z",
     "end_time": "2023-05-23T15:27:56.538124Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# load the text\n",
    "with open('../data/notebook.txt') as f:\n",
    "    notebook = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:27:57.066713Z",
     "end_time": "2023-05-23T15:27:57.070006Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# text split into chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter1 = CharacterTextSplitter(\n",
    "    separator = \"]\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "# text split 2\n",
    "text_splitter2 = CharacterTextSplitter(\n",
    "    separator = \"]\\n\",\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap  = 100,\n",
    "    length_function = len,\n",
    ")\n",
    "# text split 3\n",
    "text_splitter3= CharacterTextSplitter(\n",
    "    separator = \"]\\n\",\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:27:58.221813Z",
     "end_time": "2023-05-23T15:27:58.223990Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='[\\'# Getting started with Langchain\\\\n\\', \\'\\\\n\\', \\'In this tutorial, we will walk through the basics of using LangChain to create a simple AI chatbot that can answer questions using OpenAI and Serpapi.\\']\\n[\\'# import libraries\\\\n\\', \\'import os\\\\n\\', \\'from langchain.llms import OpenAI\\']\\n[\\'#create a new openai api key\\\\n\\', \\'#os.environ[\"OPENAI_API_KEY\"] = \"...\"\\']\\n[\\'# set up openai api key\\\\n\\', \"openai_api_key = os.environ.get(\\'OPENAI_API_KEY\\')\"]\\n[\\'### The temperature of a llm is a hyperparameter that controls the randomness of the output. It is a value between 0 and 1. A higher temperature will result in more random output. A lower temperature will result in more predictable output. For this tutorial, we will set the temperature to 0.9. You can play aroun with this yourself to see how it affects the output.\\']\\n[\\'# create a llm\\\\n\\', \\'llm = OpenAI(temperature = 0.9)\\']\\n[\\'text = \"What are 4 countries where they eat a lot of potatoes?\"\\\\n\\', \\'print(llm(text))\\'' metadata={}\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter1.create_documents([notebook])\n",
    "#texts2 = text_splitter2.create_documents([notebook])\n",
    "#texts3 = text_splitter3.create_documents([notebook])\n",
    "print(texts[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T23:43:12.525200Z",
     "end_time": "2023-05-18T23:43:12.531288Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create an index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator().from_loaders([loader])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:28:24.452308Z",
     "end_time": "2023-05-23T15:28:29.187213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "' This text is about using LangChain to create a simple AI chatbot that can answer questions using OpenAI and Serpapi. It also covers how to add memory to agents, how to set up an OpenAI API key, and how to use PromptTemplates and LLMChains.'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is the text about?\"\n",
    "index.query(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:28:36.864010Z",
     "end_time": "2023-05-23T15:28:45.273966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c9825b3d7d5b5f0ea8e92ba86986c531 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c9825b3d7d5b5f0ea8e92ba86986c531 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c9825b3d7d5b5f0ea8e92ba86986c531 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 23 May 2023 13:28:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-processing-ms': '155', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249487', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '122ms', 'x-request-id': 'c9825b3d7d5b5f0ea8e92ba86986c531', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7cbda4fbf96503a7-MAD', 'alt-svc': 'h3=\":443\"; ma=86400, h3-29=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "data": {
      "text/plain": "' This text explains how to use LangChain to create a simple AI chatbot that can answer questions using OpenAI and Serpapi. It explains how to set up an OpenAI API key and how to create a LLM with a temperature of 0.9. It also explains how to use PromptTemplates and LLMChains to generate responses to questions.'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"please give a summary of the text\"\n",
    "index.query(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:28:51.354647Z",
     "end_time": "2023-05-23T15:29:02.312746Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "1. Load the model\n",
      "2. Load in some tools to use\n",
      "3. Initialize an agent\n",
      "4. Create a new OpenAI API key\n",
      "5. Set up OpenAI API key\n",
      "6. Create a LLM with a temperature of 0.9\n",
      "7. Run the LLM with a text input\n"
     ]
    }
   ],
   "source": [
    "query = \"please give bullet points of all the steps in the text\"\n",
    "print(index.query(query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:29:02.315006Z",
     "end_time": "2023-05-23T15:29:08.698087Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "' This notebook provides a tutorial on how to use LangChain to create a simple AI chatbot that can answer questions using OpenAI and Serpapi. It covers topics such as importing libraries, setting up an OpenAI API key, creating a language model, and initializing an agent. It also covers how to add memory to the agent to make it more dynamic and interactive. By the end of the tutorial, you will have a fully functioning AI chatbot that can answer questions and have conversations.'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Write a introduction paragraph for an article about this notebook\"\n",
    "index.query(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:29:13.011314Z",
     "end_time": "2023-05-23T15:29:24.115892Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "- How to use LangChain to create a simple AI chatbot\n",
      "- How to use OpenAI and Serpapi to answer questions\n",
      "- How to set up an OpenAI API key\n",
      "- How to set the temperature of a language model\n",
      "- How to use tools, language models, and agents to interact with the world\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the key takeaways in bullet points in this notebook?\"\n",
    "print(index.query(query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:30:31.100022Z",
     "end_time": "2023-05-23T15:30:36.618327Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #import libraries, from langchain.agents import load_tools, from langchain.agents import initialize_agent, from langchain.llms import OpenAI, # Load the model, llm = OpenAI(temperature=0), Tools are functions that agents can use to interact with the world. These tools can be generic utilities (e.g. search), other chains, or even other agents., # Load in some tools to use, #os.environ[\"SERPAPI_API_KEY\"] = \"...\", tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm), # Finally, let's initialize an agent with:, 1. The tools, 2. The language model, 3. The type of agent we want to use.\n"
     ]
    }
   ],
   "source": [
    "query = \"what are the first 10 lines of code?\"\n",
    "print(index.query(query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:30:16.866693Z",
     "end_time": "2023-05-23T15:30:28.531216Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Agent article writer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('../data/notebook.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:32:39.819844Z",
     "end_time": "2023-05-23T15:32:39.823082Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# load the text\n",
    "with open('../data/notebook.txt') as f:\n",
    "    notebook = f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:32:40.427401Z",
     "end_time": "2023-05-23T15:32:40.431420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "llm = OpenAI(temperature=0)\n",
    "conversation = ConversationChain(llm=llm, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:32:41.180047Z",
     "end_time": "2023-05-23T15:32:41.184875Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: can you read the notebook.txt file for me?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Sure, I can read the notebook.txt file for you. It contains a list of notes about a project you are working on. The notes include ideas, tasks, and resources related to the project. Do you need me to read the entire file or just a specific section?'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"can you read the notebook.txt file for me?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-23T15:32:42.024890Z",
     "end_time": "2023-05-23T15:32:47.355078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: can you read the notebook.txt file for me?\n",
      "AI:  Sure, I can read the notebook.txt file for you. It contains a list of notes about a project you are working on. The notes include ideas, tasks, and resources you need to complete the project. Do you need me to read the entire file or just a specific section?\n",
      "Human: What is it about?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' The notebook.txt file contains notes about a project you are working on. The notes include ideas, tasks, and resources you need to complete the project. It also includes any other information related to the project that you have written down.'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is it about?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-18T23:46:31.121329Z",
     "end_time": "2023-05-18T23:46:36.924566Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# chain for summarization\n",
    "[Documentation](https://python.langchain.com/en/latest/modules/chains/index_examples/summarize.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
