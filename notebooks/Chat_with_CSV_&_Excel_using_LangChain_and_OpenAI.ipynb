{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chat with your csv files using Langchain and OpenAI\n",
    "\n",
    "In this notebook we will use Langchain and OpenAI to create a question-answering system for a csv file. We will use the tracklist.csv file from my spotify repository - [Github](https://github.com/rubentak/Spotify)\n",
    "\n",
    "\n",
    "\n",
    "### First install langchain, openai and chromadb if these are not installed"
   ],
   "metadata": {
    "id": "r0alwu2qZzGU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install -q langchain openai chromadb\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGXR0-MsaE1T",
    "outputId": "5d097565-7a4b-4f2b-a3f3-09a733a43f6f",
    "ExecuteTime": {
     "end_time": "2023-05-04T08:13:27.996158Z",
     "start_time": "2023-05-04T08:13:27.989429Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "import os"
   ],
   "metadata": {
    "id": "0X1EX8eRcRCk",
    "ExecuteTime": {
     "end_time": "2023-05-04T08:13:29.091373Z",
     "start_time": "2023-05-04T08:13:29.087697Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get your OpenAI Key from here - https://platform.openai.com/account/api-keys"
   ],
   "metadata": {
    "id": "aJOrUeJedzMF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set enviorment variable and download the csv file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ],
   "metadata": {
    "id": "Zmk3KQMqZvsO",
    "ExecuteTime": {
     "end_time": "2023-05-04T08:05:53.530579Z",
     "start_time": "2023-05-04T08:05:53.525956Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the documents\n",
    "loader = CSVLoader(file_path='tracklist.csv')"
   ],
   "metadata": {
    "id": "TR8dXxxHbY_b",
    "ExecuteTime": {
     "end_time": "2023-05-04T08:05:56.668534Z",
     "start_time": "2023-05-04T08:05:56.663541Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create an index using the loaded documents\n",
    "index_creator = VectorstoreIndexCreator()\n",
    "docsearch = index_creator.from_loaders([loader])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3P4s3IKXaar8",
    "outputId": "602eedc3-7adb-4871-c685-c77c43544058",
    "ExecuteTime": {
     "end_time": "2023-05-04T08:06:12.599091Z",
     "start_time": "2023-05-04T08:05:57.822596Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB without persistence: data will be transient\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-vruq68YZnmL",
    "ExecuteTime": {
     "end_time": "2023-05-04T08:06:19.611607Z",
     "start_time": "2023-05-04T08:06:19.607587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a question-answering chain using the index\n",
    "chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Pass a query to the chain\n",
    "query = \"Do you have a column called tempo?\"\n",
    "response = chain({\"question\": query})"
   ],
   "metadata": {
    "id": "Jwy7gjr0aXBr",
    "ExecuteTime": {
     "end_time": "2023-05-04T08:06:23.746192Z",
     "start_time": "2023-05-04T08:06:21.562097Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(response['result'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9D8ajM74eC_c",
    "outputId": "22175dff-7b62-495e-8d98-9928095e5778",
    "ExecuteTime": {
     "end_time": "2023-05-04T08:06:26.335403Z",
     "start_time": "2023-05-04T08:06:26.329411Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, there is a column called tempo.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "' Yes, I have a column called tempo.'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrap it in a function\n",
    "query = \"Do you have a column called tempo?\"\n",
    "def ask_question(query):\n",
    "    response = chain({\"question\": query})\n",
    "    return response['result']\n",
    "ask_question(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T08:06:35.428101Z",
     "start_time": "2023-05-04T08:06:33.258364Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Continue the conversation yourself!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 10:08:26.609 \n",
      "  \u001B[33m\u001B[1mWarning:\u001B[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/erictak/miniconda3/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "query = \"...?\"\n",
    "def ask_question(query):\n",
    "    response = chain({\"question\": query})\n",
    "    return response['result']\n",
    "ask_question(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-04T08:08:26.613504Z",
     "start_time": "2023-05-04T08:08:25.243624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
